# Gender-Detection-Machine-Learning-Model
A gender detection model based on machine learning, created for the Comys Hackathon.



# ğŸš€ Hackathon Task B: Face Recognition (Folder-wise Matching)

---

## ğŸ“Œ Task Objective:

> *Given a test face image (real or distorted), match it against its correct person folder.*

### âœ… Success Criteria:

| âœ…                                                                                                                              | Condition |
| ------------------------------------------------------------------------------------------------------------------------------ | --------- |
| âœ… If the test image (or distorted version) *matches any image inside its true person folder* â†’ *Label = 1 (Correct Match)* |           |
| âŒ If it does *not match any image from its true folder* â†’ *Label = 0 (Non-Match)*                                          |           |

---

## ğŸ“Œ Dataset Structure:


/train/
    /Person_1/
        image1.jpg
        distorted1.jpg
    /Person_2/
        image2.jpg
        distorted2.jpg
/val/
    /Person_101/
        imageX.jpg
        distortedX.jpg
    /Person_102/
        imageY.jpg
        distortedY.jpg


* âœ… Each folder = 1 unique individual
* âœ… Val contains persons not present in train
* âœ… Distorted images exist inside folders alongside real images

---

## ğŸ“Œ Solution Approach (FaceNet + Cosine Similarity Matching):

| Step                                                              | Description                                                                     |
| ----------------------------------------------------------------- | ------------------------------------------------------------------------------- |
| âœ… 1                                                               | *Use FaceNet (Pretrained on VGGFace2)* to extract face embeddings             |
| âœ… 2                                                               | *Build reference embeddings for all images* from both train and val folders   |
| âœ… 3                                                               | For each validation image:                                                      |
| â†’ *Compare its embedding with all embeddings in its own folder* |                                                                                 |
| â†’ Calculate *cosine similarity*                                 |                                                                                 |
| âœ… 4                                                               | If similarity â‰¥ threshold (0.6 used), predict *Label = 1 (Match), else **0* |
| âœ… 5                                                               | Output validation accuracy and per-image prediction logs                        |

---

## ğŸ“Œ Result âœ… âœ… âœ…:

| Metric                    | Value                                                                  |
| ------------------------- | ---------------------------------------------------------------------- |
| Final Validation Accuracy | âœ… *1.0000 (3376 / 3376)*                                             |
| Method                    | *Folder-wise matching with FaceNet embeddings and Cosine Similarity* |

---

## ğŸ“Œ How to Run:

1. âœ… Upload dataset to Google Colab (train + val folders)
2. âœ… Run FaceNet Cosine Matching notebook
3. âœ… The notebook will:

   * Build reference embeddings
   * Evaluate val set
   * Print image-wise similarity and prediction
4. âœ… For custom testing â†’ Upload any image â†’ Run final test cell

---

## ğŸ“Œ Extra: Test on Any Distorted Image:

Notebook contains a final cell where you can upload *any single image (distorted or real)*
â†’ It will tell you:

* Which person folder it matches
* Max similarity
* Predicted label (1 or 0)

---
